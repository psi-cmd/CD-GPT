{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  e:\\2025Spring_CS776\\project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "mpl.rcParams['font.size'] = 20\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "pwddir = os.path.dirname(os.path.abspath(\".\"))\n",
    "print(\"Current working directory: \", pwddir)\n",
    "sys.path.append(os.path.join(pwddir, \"src\", \"CD-GPT\"))\n",
    "\n",
    "from config import get_config\n",
    "from model import CDGPTSequencePrediction, CDGPT\n",
    "from tokenizer import SentencePieceTokenizer\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:change bos token id from -1 to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 64000\n"
     ]
    }
   ],
   "source": [
    "cfg = get_config()\n",
    "cfg.tokenizer.path = os.path.join(pwddir, \"src\", \"CD-GPT\", \"checkpoints\", \"tokenizer.model\")\n",
    "cfg.model.num_classes = 1\n",
    "tokenizer = SentencePieceTokenizer(cfg.tokenizer.path)\n",
    "cfg.tokenizer.pad_id = tokenizer.pad\n",
    "# print(\"Vocabulary:\", tokenizer.vocab)\n",
    "print(\"Number of tokens:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.piece_to_id(\"ACG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_piece(63999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([63999,   321, 63980])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"ACGT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([63999,   507])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"ACTG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBMDataset(Dataset):\n",
    "    \"\"\"\n",
    "    df: TF_Id, ArrayType, Sequence, Signal_Mean, ...\n",
    "    We parse only sequences for X and signals for Y.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, seq_col=None, tgt_col=None, \\\n",
    "                transform=None, truncate=False):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.seq_col = seq_col\n",
    "        self.tgt_col = tgt_col\n",
    "        self.df = df\n",
    "        self.truncate = truncate\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df[self.seq_col].iloc[idx]\n",
    "\n",
    "        if self.truncate:\n",
    "            seq = seq[:35]\n",
    "        val = self.df[self.tgt_col].iloc[idx]\n",
    "        if self.transform:\n",
    "            xarr = self.transform(seq)\n",
    "        \n",
    "        return xarr, float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, seq_col, tgt_col, batch_size=32, ratio=0.1, \\\n",
    "        transform=None, truncate=False):\n",
    "    train_df = df.sample(frac=1-ratio)\n",
    "    val_df = df.drop(train_df.index)\n",
    "    \n",
    "    train_set = PBMDataset(train_df, seq_col=seq_col, \n",
    "                         tgt_col=tgt_col, transform=transform, truncate=truncate)\n",
    "    val_set = PBMDataset(val_df, seq_col=seq_col,\n",
    "                         tgt_col=tgt_col, transform=transform, truncate=truncate)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24153\\AppData\\Local\\Temp\\ipykernel_40148\\2731182292.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_path, map_location=\"cpu\")\n",
      "WARNING:root:change bos token id from -1 to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1059.38M\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(pwddir, \"src\", \"CD-GPT\", \"checkpoints\", \"CD-GPT-1b.pth\")\n",
    "assert os.path.exists(model_path)\n",
    "state = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "output_head = \"sequence\"\n",
    "# assert output_head in ('sequence', 'token', 'residuepair')\n",
    "# cdgpt = CDGPTSequencePrediction(cfg)\n",
    "cdgpt = CDGPT(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint form: e:\\2025Spring_CS776\\project\\src\\CD-GPT\\checkpoints\\CD-GPT-1b.pth\n"
     ]
    }
   ],
   "source": [
    "cdgpt.load_state_dict(state[\"model\"], strict=False)\n",
    "print(f\"load checkpoint form: {model_path}\")\n",
    "cdgpt = cdgpt.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.utils import configurable\n",
    "class CDGPTRegression(CDGPT):\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, cfg):\n",
    "        pad_id = cfg.tokenizer.pad_id\n",
    "        num_classes = cfg.model.num_classes\n",
    "        return {\n",
    "            \"num_classes\": num_classes,\n",
    "            \"pad_id\": pad_id,\n",
    "            **super().from_config(cfg)\n",
    "        }\n",
    "\n",
    "    @configurable\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 vocab_size: int,\n",
    "                 max_len: int = 2048,\n",
    "                 embedding_dim=2304,\n",
    "                 num_layers: int = 12,\n",
    "                 num_heads: int = 24,\n",
    "                 bias=False,\n",
    "                 eps=1e-5,\n",
    "                 pad_id=2,\n",
    "                 dropout=0.0):\n",
    "        super().__init__(vocab_size, max_len, embedding_dim, num_layers, num_heads, bias, eps, include_head=False)\n",
    "        self.num_classes = num_classes\n",
    "        self.pad_id = pad_id\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        for name, param in self.named_parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.mlp_head = nn.Linear(self.embedding_dim, self.num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask = None,\n",
    "                pos_ids = None):\n",
    "        hiddens = super().forward(input_ids, attention_mask, pos_ids)\n",
    "        if self.pad_id is None:\n",
    "            sequence_lengths = -1  # last token for classification or regression\n",
    "        else:\n",
    "            sequence_lengths = torch.ne(input_ids, self.pad_id).sum(-1) - 1\n",
    "        batch_size = hiddens.shape[0]\n",
    "        hiddens = hiddens[torch.arange(batch_size, device=hiddens.device), sequence_lengths]\n",
    "        out = self.mlp_head(hiddens)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def train_one_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y in tqdm.tqdm(train_loader):\n",
    "        batch_x = batch_x.to(device).long()\n",
    "        batch_y = batch_y.to(device).half()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y.reshape(outputs.shape))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch_x.size(0)\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.to(device).long()\n",
    "            batch_y = batch_y.to(device).half()\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_fn(outputs, batch_y.reshape(outputs.shape))\n",
    "            total_loss += loss.item() * batch_x.size(0)\n",
    "    return total_loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArrayType</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Signal_Mean</th>\n",
       "      <th>log2_Signal_Mean</th>\n",
       "      <th>Bias_Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HK</td>\n",
       "      <td>AAAAAACAACAGGAGGGCATCATGGAGCTGTCCAGCCTGTGTGAAA...</td>\n",
       "      <td>2582.4406</td>\n",
       "      <td>11.335078</td>\n",
       "      <td>0.336051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HK</td>\n",
       "      <td>AAAAAACAGCCGGATCACAATTTTGCCGAGAGCGACCTGTGTGAAA...</td>\n",
       "      <td>4164.3662</td>\n",
       "      <td>12.024228</td>\n",
       "      <td>0.859151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HK</td>\n",
       "      <td>AAAAAACGTCCGGTACACCCCGTTCGGCGGCCCAGCCTGTGTGAAA...</td>\n",
       "      <td>3850.3552</td>\n",
       "      <td>11.911150</td>\n",
       "      <td>1.326913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK</td>\n",
       "      <td>AAAAAACTCTAGACCTTTAGCCCATCGTTGGCCAACCTGTGTGAAA...</td>\n",
       "      <td>6228.9379</td>\n",
       "      <td>12.605002</td>\n",
       "      <td>1.591492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HK</td>\n",
       "      <td>AAAAAAGAACAACCGGATAACACCCTTACAGCACACCTGTGTGAAA...</td>\n",
       "      <td>5027.6406</td>\n",
       "      <td>12.295953</td>\n",
       "      <td>0.856391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80851</th>\n",
       "      <td>ME</td>\n",
       "      <td>TTTTTTGAGGCCCAATCGTTTCGGCCGTGATGCTACCTGTGTGAAA...</td>\n",
       "      <td>19893.1972</td>\n",
       "      <td>14.280060</td>\n",
       "      <td>2.200901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80852</th>\n",
       "      <td>ME</td>\n",
       "      <td>TTTTTTGTGTACAGTGCTTGAAGACTCGAGGCCGTCCTGTGTGAAA...</td>\n",
       "      <td>15324.3828</td>\n",
       "      <td>13.903635</td>\n",
       "      <td>1.264322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80853</th>\n",
       "      <td>ME</td>\n",
       "      <td>TTTTTTTATCCCCAGCTGTTGGGATTAGGTTTGGGCCTGTGTGAAA...</td>\n",
       "      <td>15385.7968</td>\n",
       "      <td>13.909405</td>\n",
       "      <td>1.597506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80854</th>\n",
       "      <td>ME</td>\n",
       "      <td>TTTTTTTGAGCCGTAATCACAGCTGTGCACAGAGCCCTGTGTGAAA...</td>\n",
       "      <td>6923.0263</td>\n",
       "      <td>12.757395</td>\n",
       "      <td>0.490344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80855</th>\n",
       "      <td>ME</td>\n",
       "      <td>TTTTTTTGGTCCGCAGACTTCCCGTAGTTTTACTACCTGTGTGAAA...</td>\n",
       "      <td>21025.0351</td>\n",
       "      <td>14.359889</td>\n",
       "      <td>2.033061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80856 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArrayType                                           Sequence  \\\n",
       "0            HK  AAAAAACAACAGGAGGGCATCATGGAGCTGTCCAGCCTGTGTGAAA...   \n",
       "1            HK  AAAAAACAGCCGGATCACAATTTTGCCGAGAGCGACCTGTGTGAAA...   \n",
       "2            HK  AAAAAACGTCCGGTACACCCCGTTCGGCGGCCCAGCCTGTGTGAAA...   \n",
       "3            HK  AAAAAACTCTAGACCTTTAGCCCATCGTTGGCCAACCTGTGTGAAA...   \n",
       "4            HK  AAAAAAGAACAACCGGATAACACCCTTACAGCACACCTGTGTGAAA...   \n",
       "...         ...                                                ...   \n",
       "80851        ME  TTTTTTGAGGCCCAATCGTTTCGGCCGTGATGCTACCTGTGTGAAA...   \n",
       "80852        ME  TTTTTTGTGTACAGTGCTTGAAGACTCGAGGCCGTCCTGTGTGAAA...   \n",
       "80853        ME  TTTTTTTATCCCCAGCTGTTGGGATTAGGTTTGGGCCTGTGTGAAA...   \n",
       "80854        ME  TTTTTTTGAGCCGTAATCACAGCTGTGCACAGAGCCCTGTGTGAAA...   \n",
       "80855        ME  TTTTTTTGGTCCGCAGACTTCCCGTAGTTTTACTACCTGTGTGAAA...   \n",
       "\n",
       "       Signal_Mean  log2_Signal_Mean  Bias_Removed  \n",
       "0        2582.4406         11.335078      0.336051  \n",
       "1        4164.3662         12.024228      0.859151  \n",
       "2        3850.3552         11.911150      1.326913  \n",
       "3        6228.9379         12.605002      1.591492  \n",
       "4        5027.6406         12.295953      0.856391  \n",
       "...            ...               ...           ...  \n",
       "80851   19893.1972         14.280060      2.200901  \n",
       "80852   15324.3828         13.903635      1.264322  \n",
       "80853   15385.7968         13.909405      1.597506  \n",
       "80854    6923.0263         12.757395      0.490344  \n",
       "80855   21025.0351         14.359889      2.033061  \n",
       "\n",
       "[80856 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_name = \"Sp1\"\n",
    "df = pd.read_csv(f\"./data/{tf_name}.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:change bos token id from -1 to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 911.93M\n",
      "load checkpoint form: e:\\2025Spring_CS776\\project\\src\\CD-GPT\\checkpoints\\CD-GPT-1b.pth\n",
      "trainable params: 2305 || all params: 911927809 || trainable%: 0.0002527612358403252\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "split_ratio = 0.1 # 10% for validation\n",
    "lr = 1e-2\n",
    "\n",
    "max_length = 36\n",
    "cdgpt_encoder = partial(tokenizer.encode, max_length=max_length, pad=True, to_tensor=True)\n",
    "fileanme = f\"model_{tf_name}_lr{lr}_epochs{n_epochs}_batch_size{batch_size}_seed{SEED}\"\n",
    "param_file = f\"cdgpt_models/{fileanme}.pt\"\n",
    "\n",
    "train_loader, val_loader = get_dataset(df, seq_col=\"Sequence\", tgt_col=\"Bias_Removed\", \n",
    "                                       batch_size=batch_size, ratio=split_ratio, \n",
    "                                       transform=cdgpt_encoder, truncate=True)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = CDGPTRegression(cfg)\n",
    "model.load_state_dict(state[\"model\"], strict=False)\n",
    "print(f\"load checkpoint form: {model_path}\")\n",
    "model = model.half()\n",
    "model = model.to(device)\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [03:28<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: nan, Validation Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [03:27<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: nan, Validation Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [03:28<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(param_file):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    torch.save({\n",
    "        \"model_state_dict\":model.state_dict(),\n",
    "        \"train_losses\":train_losses,\n",
    "        \"val_losses\":val_losses,\n",
    "    }, param_file)\n",
    "else:\n",
    "    checkpoint = torch.load(param_file)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    train_losses = checkpoint[\"train_losses\"]\n",
    "    val_losses = checkpoint[\"val_losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "ax.plot(train_losses, c=\"blue\", label=\"Training\")\n",
    "ax.plot(val_losses, c=\"red\", label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_metrics(model, val_loader, device):\n",
    "    truths = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.to(device).long()\n",
    "            batch_y = batch_y.to(device).half()\n",
    "            outputs = model(batch_x)\n",
    "            truths.extend(batch_y.cpu().numpy().tolist())\n",
    "            predictions.extend(outputs.reshape(-1).cpu().detach().numpy().tolist())\n",
    "\n",
    "    print(f\"MSE: {mean_squared_error(truths, predictions):.2f}\")\n",
    "    print(f\"Coefficient of determination: {r2_score(truths, predictions):.2f}\")\n",
    "    print(f\"Pearson correlation: {np.corrcoef(truths, predictions)[0, 1]:.2f}\")\n",
    "    mean_val = np.mean(truths)\n",
    "    std_val = np.std(truths)\n",
    "    labels = truths > (mean_val+4*std_val)\n",
    "    print(f\"ROC AUC: {roc_auc_score(labels, predictions):.2f}\")\n",
    "    return truths, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths, predictions = run_evaluation_metrics(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({\"y\": truths, r\"$\\hat{y}$\": predictions})\n",
    "\n",
    "# scatter plot\n",
    "g = sns.JointGrid(x=\"y\", y=r\"$\\hat{y}$\", data=tmp_df)\n",
    "g = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5);\n",
    "\n",
    "# line: y_pred = y\n",
    "y_line = np.linspace(np.min(truths), np.max(truths), 200)\n",
    "g.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n",
    "\n",
    "# histograms\n",
    "g = g.plot_marginals(sns.histplot, data=tmp_df, color=\"green\", kde=False);\n",
    "\n",
    "g.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\n",
    "g.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
